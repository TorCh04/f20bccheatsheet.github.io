<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Neural Networks and Deep Learning</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="styles.css">
    <!-- Optional: MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
</head>
<body>
    <h1>Part I: Neural Networks and Deep Learning</h1>
    <div class="top-actions">
        <a class="home-btn" href="index.html" aria-label="Go to home">Home</a>
    </div>
    <div class="section">
        <h2>1.1 Logistic Regression</h2>
        <ul>
            <li>
                <strong>Linear Classifier:</strong> Logistic Regression is considered a <strong>linear classifier</strong> because it relies on a <strong>linear discriminant function</strong> to partition the feature space (i.e., separate classes using a straight line or hyperplane).
            </li>
            <li>
                <strong>Regression vs Classification:</strong> The problem determines the goal:
                <ul class="sublist">
                    <li>
                        <strong>Regression</strong> problems aim to predict a real output value (e.g., housing cost), typically finding a linear model <span class="math">\(\hat{y}=wx+b\)</span>.
                    </li>
                    <li>
                        <strong>Classification</strong> problems aim for a categorical answer (e.g., cat or dog). Logistic Regression calculates the <strong>conditional probability</strong> <span class="math">\(\hat{Y} = P(y=1|x)\)</span>, which must fall between 0 and 1. It typically uses the <strong>Cross Entropy / Log Loss function</strong> to calculate the cost.
                    </li>
                </ul>
            </li>
            <li>
                <strong>Forward Pass and Backward Pass:</strong>
                <ul class="sublist">
                    <li>
                        <strong>Forward Pass:</strong> The input vector <span class="math">\(X\)</span> propagates forward to calculate the weighted sum <span class="math">\(z = W^T X + b\)</span>, and then the predictor <span class="math">\(\hat{Y} = \sigma(z)\)</span> is calculated by applying the sigmoid function.
                    </li>
                    <li>
                        <strong>Backward Pass:</strong> This uses the chain rule to calculate the <strong>derivatives (gradients)</strong>, such as <span class="math">\(dz=a-y\)</span>, which determine how much each weight and bias contributed to the final error. These gradients are used to update the parameters.
                    </li>
                </ul>
                <img src="images/forwardbackwardpass.png" alt="Logistic Regression Forward and Backward Pass Diagram" class="diagram">
            </li>
            <li>
                <strong>Learning Rate (<span class="math">\(\alpha\)</span>):</strong> This is a <strong>hyperparameter</strong> that <strong>controls the size of the step</strong> taken in each iteration during gradient descent. A low value risks stagnation, while a high value risks oscillations or divergence (no learning).
                <img src="images/learningrate.png" alt="Learning Rate Effect Diagram" class="diagram">
            </li>

            <li>
                <strong>Bias (<span class="math">\(w_0\)</span>):</strong> The bias is an essential parameter, often viewed as another weight connected to an input that is <strong>constantly "on"</strong> (value of 1). The function of the bias is to <strong>allow shifting the entire activation curve</strong> of the neuron, adjusting the decision threshold regardless of the input features.
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>1.2 Multilayer Perceptrons (MLP)</h2>
        <ul>
            <li>
                <strong>Architecture:</strong> MLPs use a <strong>fully connected feedforward architecture</strong>, meaning every node is connected to every node in adjacent layers.
            </li>
            <li>
                <strong>Hyperparameters:</strong> These variables must be set before training begins and determine the network's structure, including <strong>the number of layers</strong>, <strong>the number of nodes in the hidden layers</strong>, and the <strong>activation functions</strong>.
            </li>
            <li>
                <strong>Universal Approximation Theory:</strong> This theorem states that a feed-forward network with even a <strong>single hidden layer</strong> containing a finite number of neurons <strong>can approximate any continuous function</strong>.
            </li>
            <li>
                <strong>Activation Functions:</strong> These must be <strong>continuous and differentiable</strong> for backpropagation to work. They should be <strong>monotonic</strong> (entirely non-increasing or non-decreasing) because non-monotonicity would lead to <strong>chaotic behaviour during training</strong>, as increasing a weight might paradoxically cause the neuron to have less influence.
                <ul class="sublist">
                    <li>
                        <strong>Sigmoid/Tanh:</strong> These are sigmoidal (S-shaped) and commonly used. Tanh has a derivative that is generally larger than sigmoid's, leading to faster training.
                    </li>
                    <li>
                        <strong>Linear Activation:</strong> If a network uses linear activation functions in all hidden layers, the network can be reduced to a <strong>single-layer ANN</strong>, restricting the model to only linear functions.
                    </li>
                </ul>
            </li>
            <li>
                <strong>Vanishing Gradient Problem:</strong> This occurs primarily with sigmoid/tanh in <strong>deep neural networks</strong>. The error signal is multiplied by the small derivative of the activation function at each step, causing the update gradient for the "front" layers to <strong>decrease exponentially</strong>. This dramatically <strong>slows down the learning process</strong> for those layers.
            </li>
            <li>
                <strong>Bias in MLP:</strong> The bias allows <strong>shifting the entire activation curve</strong>, which is essential for adjusting the decision boundary. Unlike weights, the bias <strong>has no problems of symmetry</strong> and can safely be initialised to zero, though large initial values should be avoided due to the risk of vanishing gradients.
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>1.3 Backpropagation (BP)</h2>
        <ul>
            <li>
                <strong>BP Procedure:</strong> An optimisation method based on gradient descent. It involves: <strong>Forward propagation</strong> (calculating the predictor <span class="math">\(\hat{Y}\)</span>), <strong>computing the loss</strong>, <strong>Back propagation</strong> (computing derivatives), and <strong>updating learning rules</strong>.
            </li>
            <li>
                <strong>Random Initialisation:</strong> Weights must be <strong>randomly initialised</strong> to prevent symmetry, otherwise, all hidden units would compute the same function and receive identical updates.
            </li>
            <li>
                <strong>Learning Rate:</strong> As noted above, the learning rate <span class="math">\(\alpha\)</span> determines the step size and must be carefully tuned to avoid stagnation or divergence.
            </li>
            <li>
                <strong>Real Example of BP:</strong> The process involves calculating the local gradient (<span class="math">\(\delta\)</span>) for each neuron (starting at the output) and using the learning rule <span class="math">\(w_{new} = w_{old} - \alpha \cdot \delta \cdot a\)</span> to adjust weights and biases.
                <ul class="sublist">
                    <li><span class="math">\(\alpha\)</span> (alpha): The <strong>learning rate</strong></li>
                    <li><span class="math">\(\delta\)</span> (delta): The <strong>local gradient</strong> for the neuron.</li>
                    <li><span class="math">\(a\)</span>: The <strong>activation</strong> (output value) of the neuron in the <strong>previous layer</strong> (the neuron that feeds into the current weight).</li>
                </ul>
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>1.4 Convolutional Neural Networks (CNN)</h2>
        <ul>
            <li>
                <strong>Convolution Operation:</strong> This is the core mechanism where a <strong>filter</strong> (or <strong>kernel</strong>) is <strong>slid over the input</strong> (e.g., image) to produce a <strong>feature map</strong>. The filter performs a matrix multiplication (and summation) at every location. CNNs are superior because they <strong>learn these filters directly from the data</strong>. For colour images, the filter size must match the number of input channels (e.g., a <span class="math">\(3 \times 3\)</span> filter on an RGB image is <span class="math">\(3 \times 3 \times 3\)</span>).
            </li>
            <li>
                <strong>Pooling (Max-Pooling):</strong> Pooling layers reduce the feature map size by combining features into higher-level representations. <strong>Max-pooling</strong> achieves this by taking the maximum value within a sliding window. This non-overlapping subsampling grants higher-layer representations <strong>translational invariance</strong> (recognising a pattern regardless of its exact location) and reduces computational cost.
            </li>
            <li>
                <strong>Hyperparameters:</strong> Key architectural choices include the <strong>number of features/filters</strong>, the <strong>size of the features</strong> (kernel dimension), the <strong>window size and stride</strong> for pooling, and the overall architecture (order of layers).
            </li>
            <li>
                <strong>ReLU Activation Function:</strong> <strong>Rectified Linear Units (ReLU)</strong> are typically applied after convolution. They introduce non-linearity by <strong>changing all negative values to zero</strong>.
            </li>
            <li>
                <strong>Backpropagation:</strong> Like MLPs, CNNs are trained using <strong>Backpropagation</strong> to adjust both the features in the convolutional layers (the filters) and the voting weights in the fully connected layers.
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>1.5 Deep Learning: Others</h2>
        <ul>
            <li>
                <strong>Deep Learning Architectures:</strong> Deep learning is <strong>not all about deep neural networks</strong>. Alternative architectures have been proposed, such as <strong>Deep Forest</strong> and <strong>Deep SVMs</strong>.
            </li>
            <li>
                <strong>Unsupervised Learning:</strong> Deep Learning can achieve unsupervised tasks. A primary example is the <strong>Deep Autoencoder</strong>.
            </li>
            <li>
                <strong>Deep Autoencoder:</strong> This is an unsupervised deterministic mapping algorithm that applies <strong>backpropagation</strong>. It learns an approximation to the identity function by minimising the <strong>reconstruction error</strong> between the input and the output. The goal is to force the model to learn the most robust features by reducing dimensionality.
            </li>
            <li>
                <strong>Limitations:</strong> Deep Learning is particularly <strong>good at solving pattern recognition problems</strong>.
            </li>
        </ul>
    </div>
</body>
</html>