<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Genetic Programming (GP) and Related Systems</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="styles.css">
    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
</head>
<body>
    <h1>Evolutionary Algorithms and Swarm Intelligence</h1>
    <div class="top-actions">
        <a class="home-btn" href="index.html" aria-label="Go to home">Home</a>
    </div>
    <div class="section">
        <h2>2.1 Evolutionary Algorithms (EAs)</h2>
        <ul>
            <li>
                <strong>Definition:</strong> EAs are <strong>metaheuristics</strong> that operate on a <strong>population of potential solutions</strong>. They are a type of guided random search used for <strong>optimisation problems</strong>.
            </li>
            <li>
                <strong>Core Principles:</strong> EAs apply the biological principles of <strong>Inheritance, Mutation, Selection, and Crossover/recombination</strong>.
            </li>
            <li>
                <strong>Niche:</strong> They are particularly suitable for <strong>poorly-understood problems</strong>—those that are non-linear, discontinuous, or feature multiple optima—where no other method works well.
            </li>
            <li>
                <strong>Generic Framework:</strong> The algorithm starts with generating an <strong>initial population</strong> of random solutions and evaluating their fitness. This is followed by a loop of <strong>Selection</strong> (choosing parents), <strong>Variation</strong> (applying genetic operators), and <strong>Population Update</strong> (deciding which incumbents to replace with children).
            </li>
        </ul>
        <h3>EA Workflow Steps:</h3>
        <ol>
            <li>
                <strong>Initialization</strong><br>
                - Randomly generate an initial population of candidate solutions (individuals).
            </li>
            <li>
                <strong>Evaluation</strong><br>
                - Assess the fitness of each individual using a predefined fitness function.
            </li>
            <li>
                <strong>Selection</strong><br>
                - Select individuals from the current population to become parents, typically favoring those with higher fitness (e.g., roulette wheel, tournament selection).
            </li>
            <li>
                <strong>Crossover (Recombination)</strong><br>
                - Combine pairs of parents to produce offspring, exchanging genetic material to create diversity.
            </li>
            <li>
                <strong>Mutation</strong><br>
                - Randomly alter parts of offspring solutions to introduce new genetic structures and maintain diversity.
            </li>
            <li>
                <strong>Replacement</strong><br>
                - Form the new population by replacing some or all individuals from the previous generation with offspring.
            </li>
            <li>
                <strong>Termination</strong><br>
                - Repeat steps 2–6 until a stopping criterion is met (e.g., maximum generations, satisfactory fitness).
            </li>
        </ol>
        <ul>
            <li>
                <strong>Fitness Function:</strong> A function <span class="math">\(f(s)\)</span> that assigns a <strong>fitness score</strong> to any candidate solution <span class="math">\(s\)</span>. The goal of the EA is to <strong>optimise this value</strong>.
            </li>
            <li>
                <strong>Encoding:</strong> The <strong>encoding</strong> or <strong>representation</strong> is the data structure used to specify a solution (e.g., a string of bits, a tree, a list of real numbers). The choice of encoding influences the possible genetic operators and the size of the search space.
            </li>
        </ul>
        <img src="images/EAs.png" alt="Evolutionary Algorithm Workflow Diagram" class="diagram">
    </div>

    <div class="section">
        <h2>2.2 EA Details and Selection</h2>
        <ul>
            <li>
                <strong>Selection:</strong> The method used to choose parents from the population, ensuring that <strong>fitter individuals are more likely to be selected</strong>. Selection represents the strategy for deciding which areas of the search space to focus on.
            </li>
            <li>
                <strong>Selection Pressure:</strong> This is the <strong>level of prioritisation of fitter individuals</strong>. It is required to direct the EA towards an optimum.
                <ul class="sublist">
                    <li><strong>Too high pressure</strong> reduces <strong>genetic diversity</strong>, leading to the risk of <strong>premature convergence to a local optimum</strong>.</li>
                    <li><strong>Too low pressure</strong> means there is effectively <strong>no evolutionary progress</strong> and the EA may not converge in a reasonable time.</li>
                </ul>
            </li>
            <li>
                <strong>Selection Methods:</strong>
                <ul class="sublist">
                    <li>
                        <strong>Roulette Wheel Selection</strong> (Fitness Proportionate Selection): The probability of selecting an individual is directly proportional to its fitness.
                    </li>
                    <li>
                        <strong>Tournament Selection:</strong> Choose <span class="math">\(t\)</span> random individuals from the population, and the best of these <span class="math">\(t\)</span> individuals is returned. This method is highly <strong>tunable</strong> and avoids problems caused by superfit solutions.
                    </li>
                </ul>
            </li>
            <li>
                <strong>Stopping Criteria:</strong> The evolution is typically stopped when criteria such as the <strong>maximum number of generations</strong>, the maximum number of generations <strong>without improvement</strong>, or the maximum number of improvements are met.
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>2.3 Swarm Intelligence</h2>
        <ul>
            <li>
                <strong>General Properties:</strong> Swarm behaviour exhibits <strong>emergence</strong> (complex behaviour from simple interactions), <strong>distributed behaviour</strong> (making it <strong>robust to failure</strong>), and individuals generally lack awareness of the bigger picture (only observing neighbours).
            </li>
            <li>
                <strong>Boids:</strong> A model demonstrating realistic flocking behaviour based on three simple rules:
                <ol class="sublist">
                    <li><strong>Separation:</strong> Avoid getting too close to local flock mates.</li>
                    <li><strong>Alignment:</strong> Match velocity to the average velocity of local flock mates.</li>
                    <li><strong>Cohesion:</strong> Adjust velocity toward the centroid of the flock mates.</li>
                </ol>
            </li>
            <li>
                <strong>Ant Colony Optimisation (ACO):</strong>
                <ul class="sublist">
                    <li>
                        <strong>Stigmergy:</strong> This is the core concept where information is <strong>indirectly shared through changes made to an environment</strong> (e.g., pheromone trails).
                    </li>
                    <li>
                        <strong>Mechanism:</strong> ACO applies this idea to combinatorial optimisation problems (like the <strong>Travelling Salesperson Problem</strong>). Virtual ants build trails in a graph, choosing edges based on existing <strong>pheromone concentrations</strong>. The best trails receive increased pheromone deposition (often inversely proportional to length), while <strong>pheromone evaporation</strong> causes sub-optimal trails to gradually be forgotten.
                    </li>
                </ul>
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>2.4 Particle Swarm Optimisation (PSO)</h2>
        <ul>
            <li>
                <strong>Difference from EAs:</strong> PSO is distinct from EAs because each search point (particle) has an explicit <strong>velocity</strong> vector in addition to its position vector, whereas an EA search point does not. Particles are neither created nor destroyed, unlike in EAs.
            </li>
            <li>
                <strong>Particle State:</strong> Each particle maintains a <strong>position</strong> (list of numbers), a <strong>velocity</strong> (list of numbers), its <strong>personal best position</strong> (<span class="math">\(x^*_i\)</span>), and the <strong>best position seen by its informants</strong> (<span class="math">\(x^+_i\)</span>).
            </li>
            <li>
                <strong>Velocity Update:</strong> The particle's new velocity is the sum of three components:
                <ol class="sublist">
                    <li><strong>Inertia</strong> (<span class="math">\(a \cdot v_i\)</span>): Keeps the particle moving in the same general direction.</li>
                    <li><strong>Cognitive Component</strong> (<span class="math">\(b \cdot (x^*_{i} - x_i)\)</span>): Tweaks velocity toward the particle's <strong>personal best position</strong>.</li>
                    <li><strong>Social Component</strong> (<span class="math">\(c \cdot (x^+_i - x_i)\)</span>): Tweaks velocity toward the best position seen by its <strong>informants</strong>.</li>
                </ol>
            </li>
            <li>
                <strong>Informants:</strong> Informants are other particles whose best search experiences guide a particle. Using overlapping groups of informants causes knowledge to <strong>percolate gradually</strong>, which <strong>reduces the likelihood of premature convergence</strong> compared to relying on a global best position.
            </li>
            <li>
                <strong>Hyperparameters:</strong> Key hyperparameters include the <strong>swarm size</strong>, the <strong>inertia weight</strong> (<span class="math">\(a\)</span>), and the weights for the cognitive (<span class="math">\(b\)</span>) and social (<span class="math">\(c\)</span>) components, as well as the number of iterations.
            </li>
        </ul>
    </div>
    <h1>Genetic Programming (GP) and Related Systems</h1>

    <div class="section">
        <h2>3.1 Genetic Programming (GP) Overview</h2>
        <ul>
            <li>
                <strong>Goal:</strong> GP is a form of EA used to <strong>evolve programs</strong> (or executable structures). It is used when the program logic needed to solve a problem is <strong>unknown</strong>.
            </li>
            <li>
                <strong>Representation:</strong> Programs are represented as data structures, such as a <strong>parse tree</strong> (Koza GP) or a <strong>list of grammar transitions</strong> (GE). The representation influences evolvability and the size of the search space.
            </li>
            <li>
                <strong>Koza GP and Trees:</strong> The best-known form uses <strong>parse trees</strong> composed of <strong>functions</strong> (internal nodes) and <strong>terminals</strong> (leaf nodes).
                <ul class="sublist">
                    <li>
                        <strong>Closure:</strong> A fundamental requirement that <strong>all functions must be able to handle any input they may receive</strong> to maintain program validity and avoid runtime errors.
                    </li>
                    <li>
                        <strong>Bloat:</strong> The tendency for programs (especially trees) to <strong>grow large</strong> unnecessarily during evolution, leading to inefficient and difficult-to-interpret programs. Bloat can be controlled by applying <strong>depth constraints</strong> or <strong>parsimony pressure</strong> (penalising size).
                    </li>
                </ul>
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>3.2 Specific GP and Improvement Methods</h2>
        <table>
            <thead>
                <tr>
                    <th>Name</th>
                    <th>Representation</th>
                    <th>Strengths</th>
                    <th>Weaknesses</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Koza GP</strong></td>
                    <td><strong>Parse tree</strong> of functions/terminals</td>
                    <td>Well known, widely supported.</td>
                    <td>Does not use real languages, <strong>tends to bloat</strong>.</td>
                </tr>
                <tr>
                    <td><strong>Cartesian GP (CGP)</strong></td>
                    <td><strong>Graph/grid</strong> of interconnected functions</td>
                    <td>Supports implicit reuse, <strong>No bloat</strong> (fixed size).</td>
                    <td>Does not use real languages, fixed grid size.</td>
                </tr>
                <tr>
                    <td><strong>Linear GP</strong></td>
                    <td><strong>Vector/list of instructions</strong></td>
                    <td>Supports low-level languages (e.g., Java bytecode), relatively fast.</td>
                    <td>Doesn't work well with high-level languages.</td>
                </tr>
                <tr>
                    <td><strong>Grammatical Evolution (GE)</strong></td>
                    <td><strong>Vector/list of grammar transitions</strong> (numbers)</td>
                    <td>Supports <strong>high-level languages</strong> using a defined grammar; generated programs are guaranteed to be syntactically valid.</td>
                    <td>Issues with evolvability, limited grammar size.</td>
                </tr>
                <tr>
                    <td><strong>Genetic Improvement (GI)</strong></td>
                    <td><strong>Patches</strong> (lines of code to insert and delete)</td>
                    <td>Does not need to evolve everything from scratch, improves existing code.</td>
                    <td>Needs <strong>unit tests</strong> to maintain correctness.</td>
                </tr>
            </tbody>
        </table>
    </div>

    <div class="section">
        <h2>3.3 Multi-objective Evolutionary Algorithms (MOEAs)</h2>
        <ul>
            <li>
                <strong>Problem Domain:</strong> MOEAs are necessary for problems that have <strong>multiple, often conflicting, objectives</strong> (e.g., maximising accuracy and minimising complexity).
            </li>
            <li>
                <strong>Dominance:</strong> Used to compare solutions: Solution A <strong>dominates</strong> Solution B if A is better in <strong>at least one objective</strong> and no worse in all others.
            </li>
            <li>
                <strong>Pareto Front/Set:</strong> The set of all <strong>non-dominated solutions</strong> in the search space is the <strong>Pareto Optimal Set</strong>. The <strong>Pareto Optimal Front</strong> is the visualization of this set in the objective space.
            </li>
            <li>
                <strong>Goal:</strong> The aim is to produce a <strong>diverse set of solutions</strong> that represent the best possible trade-offs. The user then selects the final optimal solution from this front.
            </li>
            <li>
                <strong>NSGA-II:</strong> This widely used algorithm (Non-dominated Sorting Genetic Algorithm version 2) achieves its goals using two primary mechanisms:
                <ol class="sublist">
                    <li><strong>Ranking:</strong> Solutions are assigned a rank based on which non-dominated front they belong to (Rank 1 is the best).</li>
                    <li><strong>Sparsity (Crowding Distance):</strong> Used to measure the distance between neighboring solutions on a front. This measure ensures that a good <strong>spread (diversity)</strong> of solutions is maintained along the Pareto front.</li>
                </ol>
            </li>
            <li>
                <strong>Benefit for GP:</strong> MOEAs can be used to <strong>control bloat in GP</strong> by including program size as a secondary objective, rewarding simpler solutions.
            </li>
        </ul>
    </div>

    <h1>Other Bio-Inspired Models</h1>
    <div class="section">
        <h2>4.1 Cellular Automata (CA)</h2>
        <ul>
            <li>
                <strong>Definition:</strong> CAs are models of <strong>distributed emergent behaviour</strong> operating on a grid (1D, 2D, or more dimensions) over <strong>discrete time steps</strong>. Complex behavior emerges from simple, identical <strong>update rules</strong> applied to a local <strong>neighbourhood</strong>.
            </li>
            <li>
                <strong>Use Cases:</strong> Used for modelling <strong>spatial processes</strong> (like forest fires), physical, and biological processes, and solving computational problems.
            </li>
            <li>
                <strong>Elementary CA (ECA):</strong> These are <strong>1D binary CAs</strong> (state is 0 or 1) that use a neighbourhood of size 3. Since <span class="math">\(2^3=8\)</span> patterns map to a binary output, there are <span class="math">\(2^8=256\)</span> possible update rules, each having a unique number (0 to 255). ECA Rule 110 is famously known to be <strong>Turing complete</strong> (capable of universal computation).
            </li>
            <li>
                <strong>The Game of Life:</strong> A 2D CA that uses <strong>2 states</strong> and a <strong>Moore neighbourhood</strong> (8 neighbours + cell itself). It is defined by 4 rules (under-population, survival, over-crowding, reproduction). It exhibits <strong>surprisingly complex behaviour</strong> and is <strong>Turing complete</strong>. Moving elements like <strong>gliders</strong> and <strong>spaceships</strong> emerge from its rules.
            </li>
        </ul>
    </div>
</body>
</html>