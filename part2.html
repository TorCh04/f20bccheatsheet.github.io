<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Evolutionary Algorithms and Swarm Intelligence</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
     <link rel="stylesheet" href="styles.css">
    <!-- MathJax for LaTeX rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
</head>
<body>
    <h1>Part II: Evolutionary Algorithms and Swarm Intelligence</h1>
<div class="top-actions">
        <a class="home-btn" href="index.html" aria-label="Go to home">Home</a>
    </div>
    <div class="section">
        <h2>2.1 Evolutionary Algorithms (EAs)</h2>
        <ul>
            <li>
                <strong>Definition:</strong> EAs are <strong>metaheuristics</strong> that operate on a <strong>population of potential solutions</strong>. They are a type of guided random search used for <strong>optimisation problems</strong>.
            </li>
            <li>
                <strong>Core Principles:</strong> EAs apply the biological principles of <strong>Inheritance, Mutation, Selection, and Crossover/recombination</strong>.
            </li>
            <li>
                <strong>Niche:</strong> They are particularly suitable for <strong>poorly-understood problems</strong>—those that are non-linear, discontinuous, or feature multiple optima—where no other method works well.
            </li>
            <li>
                <strong>Generic Framework:</strong> The algorithm starts with generating an <strong>initial population</strong> of random solutions and evaluating their fitness. This is followed by a loop of <strong>Selection</strong> (choosing parents), <strong>Variation</strong> (applying genetic operators), and <strong>Population Update</strong> (deciding which incumbents to replace with children).
            </li>
            <li>
                <strong>Fitness Function:</strong> A function <span class="math">\(f(s)\)</span> that assigns a <strong>fitness score</strong> to any candidate solution <span class="math">\(s\)</span>. The goal of the EA is to <strong>optimise this value</strong>.
            </li>
            <li>
                <strong>Encoding:</strong> The <strong>encoding</strong> or <strong>representation</strong> is the data structure used to specify a solution (e.g., a string of bits, a tree, a list of real numbers). The choice of encoding influences the possible genetic operators and the size of the search space.
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>2.2 EA Details and Selection</h2>
        <ul>
            <li>
                <strong>Selection:</strong> The method used to choose parents from the population, ensuring that <strong>fitter individuals are more likely to be selected</strong>. Selection represents the strategy for deciding which areas of the search space to focus on.
            </li>
            <li>
                <strong>Selection Pressure:</strong> This is the <strong>level of prioritisation of fitter individuals</strong>. It is required to direct the EA towards an optimum.
                <ul class="sublist">
                    <li><strong>Too high pressure</strong> reduces <strong>genetic diversity</strong>, leading to the risk of <strong>premature convergence to a local optimum</strong>.</li>
                    <li><strong>Too low pressure</strong> means there is effectively <strong>no evolutionary progress</strong> and the EA may not converge in a reasonable time.</li>
                </ul>
            </li>
            <li>
                <strong>Selection Methods:</strong>
                <ul class="sublist">
                    <li>
                        <strong>Roulette Wheel Selection</strong> (Fitness Proportionate Selection): The probability of selecting an individual is directly proportional to its fitness.
                    </li>
                    <li>
                        <strong>Tournament Selection:</strong> Choose <span class="math">\(t\)</span> random individuals from the population, and the best of these <span class="math">\(t\)</span> individuals is returned. This method is highly <strong>tunable</strong> and avoids problems caused by superfit solutions.
                    </li>
                </ul>
            </li>
            <li>
                <strong>Stopping Criteria:</strong> The evolution is typically stopped when criteria such as the <strong>maximum number of generations</strong>, the maximum number of generations <strong>without improvement</strong>, or the maximum number of improvements are met.
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>2.3 Swarm Intelligence</h2>
        <ul>
            <li>
                <strong>General Properties:</strong> Swarm behaviour exhibits <strong>emergence</strong> (complex behaviour from simple interactions), <strong>distributed behaviour</strong> (making it <strong>robust to failure</strong>), and individuals generally lack awareness of the bigger picture (only observing neighbours).
            </li>
            <li>
                <strong>Boids:</strong> A model demonstrating realistic flocking behaviour based on three simple rules:
                <ol class="sublist">
                    <li><strong>Separation:</strong> Avoid getting too close to local flock mates.</li>
                    <li><strong>Alignment:</strong> Match velocity to the average velocity of local flock mates.</li>
                    <li><strong>Cohesion:</strong> Adjust velocity toward the centroid of the flock mates.</li>
                </ol>
            </li>
            <li>
                <strong>Ant Colony Optimisation (ACO):</strong>
                <ul class="sublist">
                    <li>
                        <strong>Stigmergy:</strong> This is the core concept where information is <strong>indirectly shared through changes made to an environment</strong> (e.g., pheromone trails).
                    </li>
                    <li>
                        <strong>Mechanism:</strong> ACO applies this idea to combinatorial optimisation problems (like the <strong>Travelling Salesperson Problem</strong>). Virtual ants build trails in a graph, choosing edges based on existing <strong>pheromone concentrations</strong>. The best trails receive increased pheromone deposition (often inversely proportional to length), while <strong>pheromone evaporation</strong> causes sub-optimal trails to gradually be forgotten.
                    </li>
                </ul>
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>2.4 Particle Swarm Optimisation (PSO)</h2>
        <ul>
            <li>
                <strong>Difference from EAs:</strong> PSO is distinct from EAs because each search point (particle) has an explicit <strong>velocity</strong> vector in addition to its position vector, whereas an EA search point does not. Particles are neither created nor destroyed, unlike in EAs.
            </li>
            <li>
                <strong>Particle State:</strong> Each particle maintains a <strong>position</strong> (list of numbers), a <strong>velocity</strong> (list of numbers), its <strong>personal best position</strong> (<span class="math">\(x^*_i\)</span>), and the <strong>best position seen by its informants</strong> (<span class="math">\(x^+_i\)</span>).
            </li>
            <li>
                <strong>Velocity Update:</strong> The particle's new velocity is the sum of three components:
                <ol class="sublist">
                    <li><strong>Inertia</strong> (<span class="math">\(a \cdot v_i\)</span>): Keeps the particle moving in the same general direction.</li>
                    <li><strong>Cognitive Component</strong> (<span class="math">\(b \cdot (x^*_{i} - x_i)\)</span>): Tweaks velocity toward the particle's <strong>personal best position</strong>.</li>
                    <li><strong>Social Component</strong> (<span class="math">\(c \cdot (x^+_i - x_i)\)</span>): Tweaks velocity toward the best position seen by its <strong>informants</strong>.</li>
                </ol>
            </li>
            <li>
                <strong>Informants:</strong> Informants are other particles whose best search experiences guide a particle. Using overlapping groups of informants causes knowledge to <strong>percolate gradually</strong>, which <strong>reduces the likelihood of premature convergence</strong> compared to relying on a global best position.
            </li>
            <li>
                <strong>Hyperparameters:</strong> Key hyperparameters include the <strong>swarm size</strong>, the <strong>inertia weight</strong> (<span class="math">\(a\)</span>), and the weights for the cognitive (<span class="math">\(b\)</span>) and social (<span class="math">\(c\)</span>) components, as well as the number of iterations.
            </li>
        </ul>
    </div>
</body>
</html>